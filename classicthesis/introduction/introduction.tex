\chapter*{Introduction}\addcontentsline{toc}{chapter}{Introduction}
\markboth{INTRODUCTION}{INTRODUCTION}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\label{ch_introduction}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


The Standard Model (SM) of particle physics is the theory that describes and unifies three of the four fundamental interactions in Nature: electromagnetism, the weak interaction, and the strong interaction. The theoretical framework in which the SM is formulated is that of Quantum Field Theory (QFT), and the particular theory that describes the strong interaction is Quantum Chromodynamics or QCD\footnote{All relevant references in this Introduction can be found in Chapter~\ref{ch_foundation}}.

\section*{Quantum Field Theory and the Standard Model}

The 20th century saw two great developments for modern physics and our understanding of Nature: special relativity and quantum mechanics. 

The theory of special relativity reformulates Galileo's principle that the laws of physics must be left unchanged between two different inertial frames in such a way that the speed of light is a universal constant, consistent with the theory of electromagnetism developed by Maxwell in the 19th century. This brought incredible consequences, such as time and length dilation, according to which one observer experiences time and distances different from another depending on the speed they travel. Also the equivalence of mass and energy, as well as the formulation of 4-dimensional space-time as the manifold of the Universe, in which there is a non trivial interplay between time and space, as can be seen from the Lorentz transformations.

The principle of a constant speed of light and that nothing can travel faster than it rendered the old Newtonian view of interactions outdated. According to the latter, the force acting on a particle depends on the position of all other particles at that given time. This implies instantaneous transmission of the force from one particle to another, which is at odds with special relativity. Field Theory is the framework that allows to supersede this difficulty. It is based on the concept of fields, which are dynamical objects that fill all of space-time. Mathematically they are just functions of space and time. Treating fields as the basic degrees of freedom helps enormously in the task of formulating theories that are Lorentz invariant and thus compatible with special relativity. One example is Maxwell's theory of electromagnetism, governing the dynamics of the electric $\vec{E}(\vec{x},t)$ and magnetic $\vec{B}(\vec{x},t)$ fields.

On the other hand, quantum mechanics introduces the concept of probability into our description of Nature. The basic idea is that particles are described by wave functions that represent the density probability of finding one particle at a given position in space. Position and momentum are promoted to conjugate operators rather than being degrees of freedom. These operators do not commute, which gives rise to Heisenberg's uncertainty principle, by which we cannot know simultaneously the position and momentum of a particle
\begin{equation*}
\Delta x\Delta p\geq\hbar.
\end{equation*} 

Quantum Field Theory is the framework which unifies quantum mechanics and special relativity. It consists in promoting classical fields to quantum operators, like position and momentum are in quantum mechanics. This results in a plethora of consequences, like particles being excitations of some underlying quantum field, the existence of antiparticles and non conservation of particle number. The latter is of particular importance for any quantum description of a relativistic system, since high-energy collisions can create and annihilate particles. Furthermore, according to Heisenberg's uncertainty principle, if we place a particle in a box of size $L$ we have an uncertainty in its momentum of
\begin{equation*}
\Delta p\geq\hbar/L.
\end{equation*}
This is turn leads to an uncertainty in the energy of the particle of order $\Delta E\geq\hbar c/L$. When the energy exceeds $2mc^2$ we have enough energy to create out of the vacuum a particle-antiparticle pair. This will happen at distances of order 
\begin{equation*}
L=\lambda=\frac{\hbar}{mc},
\end{equation*}
which is the Compton wavelength. At this and smaller distances (or equivalently higher energies) one expects to detect particle-antiparticle pairs swarming around the original particle, breaking down the very concept of a point-like particle. 

Generalizing the concept of fields such that all particles are excitations of some field solves another puzzle of Nature: how can e.g. two electrons separated a space-like distance (causally disconnected) look exactly the same, like two perfect copies? This is naturally explained if there is a universal field of the electron, since all electrons are simply manifestations of this field filling all of space-time. 

A key ingredient to QFTs are symmetries, which are described by the mathematical language of groups. Global symmetries are of utmost importance in physics, since they provide with conservation laws through Noether's theorem, like conservation of energy and momentum. On the other hand, local or gauge symmetries play a crucial role in QFTs. These can be seen as a redundancy of the theory, such that performing some local rotation to the fundamental fields leaves physics unchanged. Though it seems unpractical to write our theories of Nature in a redundant way, it is very useful, since they allow us to write simple Lagrangians which may have unphysical degrees of freedom that can be eliminated by use of gauge redundancy. Such is the case of the polarization of the photon, which is described by a gauge field $A_{\mu}$ with four different polarizations, though only two are physical. Thanks to gauge symmetry one can eliminate the two unphysical degrees of freedom. Another beautiful property of gauge symmetries is that they allow for a geometric interpretation of interactions, thanks to the fact that Lie groups are both groups and differentiable manifolds. For example, the interaction of a photon and a electron can be understood in terms of the parallel transport of the latter along the manifold of the $U(1)$ gauge group. The photon appears as the connection between two points in the manifold of this Lie group, and the field strength tensor as the curvature. This way, all fundamental interactions of Nature can be understood in the light of geometry, like gravity is in General Relativity.

The gauge symmetry group of the SM is
\begin{equation}
SU(3)_{\textrm{c}}\times SU(2)_{\textrm{w}}\times U(1)_{\textrm{Y}},
\end{equation}
with $SU(3)_{\textrm{c}}$ the gauge group of the strong interaction (whose charge is called color), $SU(2)_{\textrm{w}}$ the gauge group of the weak interaction and $U(1)_{\textrm{Y}}$ the gauge group of hypercharge. The Higgs mechanism provides with a description of the Spontaneous Symmetry Breaking of the electroweak sector $SU(2)_{\textrm{w}}\times U(1)_{\textrm{Y}}$ into that of electromagnetism $U(1)_{\textrm{em}}$, as well as a mechanism for the generation of masses for fundamental particles. The pure gauge interactions depend only on three free parameters, which are the three coupling constants. Matter fields do not add any other free parameter, while adding the Higgs field includes 22 new free parameters into the theory, which govern the masses of elementary particles, flavor mixing angles and CP-violating phases.

Along the decades the SM has proven extremely successful in passing experimental tests. Some examples are the discovery of neutral weak currents in 1973, the discovery of the Z and W bosons in 1983 and the agreement of the ratio of their masses between experiment and theory, the discovery of the bottom and top quarks in 1977 and 1995 respectively, or the discovery of the Higgs boson in 2012. 

Despite the astonishing success of the SM, we know it cannot be the whole story. To begin with, it does not explain one of the four fundamental interactions of Nature, gravity. On the other hand, there's no candidate particle in the SM for dark matter, which we know accounts for about 85\% of the matter in the Universe. In addition to this, there are other theoretical puzzles, like the hierarchy problem of the Higgs mass, triviality of the Higgs coupling, the flavor puzzle or the strong CP problem, to quote a few. All this points to the fact that the SM is an effective theory that describes extremely well the Universe at the energy scales probed by modern day colliders, but that there must be some new physics lurking at high energies. Search for New Physics (NP) is the holy grail of modern day particle physics. 

One way to search for NP is to perform precision tests of the SM. This involves making high precision theoretical predictions and comparing them to high precision experiments. This allows to disentangle subtle NP effects that may affect processes accessible to nowadays colliders. In this respect, low-energy QCD is a rich arena to look for NP effects. One good place where to look is at Flavor Changing Neutral Currents (FCNC). These are heavily suppressed by the GIM mechanism in the SM, and thus are expected to be more sensitive to NP effects. On the other hand, in recent years some anomalies have been observed in processes involving B meson decays. In all these processes, QCD plays a crucial role, and thus precise theoretical predictions in this sector of the SM are of utmost importance.

\section*{Why Lattice Field Theory?}

When computing physical observables in QFTs divergences appear which must be removed in order for the theory to be predictive. This is done by the renormalization program, which consists in subtracting divergences appearing in physical quantities by redefining the parameters of the theory which are not observables, like field normalizations, masses and couplings. This renormalization program has been applied successfully to the three fundamental interactions described by the SM.

Renormalization introduces the concept of running of coupling constants. These are taken to run with the energy in such a way that physical observables remain finite and independent of the energy scale at which infinites are subtracted in the renormalization program.  In the case of electromagnetism, the coupling (the electron electric charge) decreases at low energies. However, in the case of Yang-Mills theories, which are QFTs whose gauge group is a Lie group, the opposite is true, and the coupling becomes stronger at lower energies. QCD is a Yang-Mills theory coupled to matter.

The technology usually employed to study Quantum Field Theory is perturbation theory. It consists in expanding expectation values in powers of the coupling of the theory, which must be smaller than 1 in order for the series to be convergent. Perturbation theory can thus be applied for the study of Quantum Electrodynamics at low energies, but not for the study of QCD at these energies. The only other known first-principles method to study QFTs is Lattice Field Theory. It consists in discretizing space-time into a grid or lattice, with space-time points separated by a non-zero lattice spacing $a$, and Wick rotating to the Euclidean. This allows to treat the theory as a statistical physics system, computing integrals and expectation values numerically. This approach enables to make reliable predictions of non-perturbative phenomena present in the SM such as low-energy QCD, and thus is of utmost relevance for precision tests of the SM and search of NP. 

Non-perturbative treatment of QCD is not only needed for the search of NP. It is also crucial to understand QCD and thus the SM itself, since most of the interesting phenomena of QCD appear due to it being strongly coupled at low energies. This is responsible for the phenomenon of confinement, by which no color charged particles are observed in Nature at low energies. Spontaneous chiral symmetry breaking is also caused by non-perturbative effects, and is responsible for the light mass of pions. It is also expected that a mass gap is dynamically generated by the theory due to its non-perturbative character. This means that the spectrum of QCD (or any other Yang-Mills theory) contains no arbitrarily light particles. This is confirmed experimentally but there is no definite theoretical proof that QCD predicts such a mass gap, though numerical simulations using Lattice Field Theory indicate the existence of it. A definite theoretical proof is one of the famous Millennium Prize Problems. Another important aspect of QCD is to understand its vacuum and the role of the $\theta$-term and topology of the gauge group. Again, to this task is of crucial importance a non-perturbative treatment of the theory.

Non-perturbative treatment of QFT is also crucial for other theoretical reasons beyond QCD. In many popular Beyond the Standard Model (BSM) theories, non-perturbative effects play a central role: in SUSY, non-perturbative effects are invoked to break SUSY at low energies. Also, nearly conformal field theories and technicolor models (which are up-scale version of QCD) require a non-perturbative treatment. More importantly, the SM version of the Higgs potential suffers from the triviality problem. This means that the renormalized Higgs coupling vanishes after perturbative renormalization except if there is a finite energy cutoff in the theory, meaning that the SM is nothing but an Effective Field Theory (EFT) valid up to some energy cutoff. If this is the case, it is expected that the Higgs mass receives large contributions from the high-energy scales, making it naturally heavy, as opposed to what is measured at CERN. This is referred to as the hierarchy problem. Non-perturbative numerical approaches show triviality of scalar quartic theories (which is the case of the Higgs potential in the SM). However, coupling this scalar to other particle content as in the SM could change the triviality behavior of the coupling. Again, these issues can only be tackled with using non-perturbative approaches.

\section*{A Mixed Action Lattice approach to light and charm physics}

We have already motivated the need for precision calculations of SM physics involving the strong interaction in order to constrain the search for NP in experiments. In this thesis we are interested in the definition and setting of a mixed action approach for the study of light and charm physics with Lattice QCD. This mixed action uses the Wilson fermion regularization for quarks in the sea, with mass degenerate up/down flavors plus a strange quark, and the Wilson twisted mass regularization for quarks in the valence, with up/down, strange and charm quarks. When tuning the twisted mass quarks at maximal twist, systematic effects of order $\mathcal{O}(a)$ coming from the discretization of space-time are expected to cancel, improving the scaling of physical observables towards the continuum. This is of relevance for the study of charm physics, since the discretization effects associated to the charm quark are of order $\mathcal{O}(am_c)$ and large due to the heavy mass of the charm $m_c$. Thus our mixed action is expected to substantially help in the extraction of precision charm observables with a controlled continuum limit.

The use of this mixed action breaks unitarity of the theory, even in the continuum, due to the use of different lattice regularizations for the sea and valence sectors. In order to correct for this effect we must match the physical quark masses in both sectors. Since the sea contains only up/down and strange quarks, we need to tune the parameters of the mixed action in order to impose that the valence up/down and strange physical quark masses are the same as the ones in the sea. This involves precise calculations in the light and strange sectors of QCD, which is what we focus on in this thesis.

Furthermore, in Lattice Field Theory any physical quantity is computed in units of the lattice spacing $a$. Thus in order to make predictions, one needs to find the value of $a$ in physical units to convert any prediction in the lattice to physical units. This task is called scale setting, and is one of the main focus of this thesis. As computations in Lattice Field Theory have become more and more precise in the recent years, setting the scale with a high accuracy has become one of the main tasks for the community. This is so because its determination affects any prediction of the theory, and in particular its uncertainty affects any other quantity we want to express in physical units.

The thesis is structured as follows. In Chapter \ref{ch_foundation} we introduce the QCD action in the continuum and its gauge structure. Then we review how it can be formulated in a lattice with finite lattice spacing $a$. We explain how expectation values are computed numerically bridging the gap between the path integral formalism and statistical mechanics. We explain how the continuum limit is taken and its relation to renormalizability in the continuum. We review the Symanzik improvement program thought to reduce the discretization systematic effects and help in the task of taking the continuum limit. We also explain the program of setting the scale. In Chapter \ref{ch_observables} we define all the relevant physical observables that we will need in this thesis and how they are extracted in the lattice. These are meson masses, decay constants, PCAC quark masses and the Wilson gradient flow scale $t_0$. We also explain how do we extract the ground state signals of these observables, isolating them from excited states, using model variation techniques. In Chapter \ref{ch_ma} we introduce our mixed action regularization. We explain the differences between the sea and valence sectors, and perform the matching between both to impose equality of the physical quark masses in both sectors. We simultaneously tune the valence to maximal twist in order to obtain $\mathcal{O}(a)$ improvement. We also introduce the line of constant physics followed by the ensembles under study and the mass shifting procedure needed to correct for small mistunings along it. In Chapter \ref{ch_ss} we perform the scale setting of our mixed action by computing the gradient flow scale $t_0$ in physical units, using as external physical input the decay constants of the pion and kaon. We explore a set of different models to make the chiral extrapolation to the physical pion mass and the continuum limit to $a\to0$. We use model averaging techniques to compute a final average result of $t_0$ in physical units accounting for the systematic uncertainty coming from the model variation. Treating $t_0$ as an intermediate scale allows to extract the lattice spacing in fm. Finally we present our conclusions in Chapter \ref{ch_conclu}. 

This thesis is supplemented with a set of appendices. In Appendix \ref{appex_conventions} we present some conventions regarding the Gamma matrices, quark bilinears and the twisted and physical basis used in the different lattice regularizations. In Appendix \ref{apex_ensembles} we review the gauge ensembles used in this work. In Appendix \ref{appex_simulations} we review some useful simulation details of Lattice Field Theories. We give details on the error propagation and treatment of (auto)correlations in Appendix \ref{appex_errors}. In Appendix \ref{appex_solvers} we briefly discuss how the Dirac operator needed to compute n-point functions is inverted in the lattice. In Appendix \ref{apex_chisq} we give details on the fitting strategy we follow throughout this work. In Appendix \ref{apex_fv} we give expressions for correcting finite volume effects as given by Chiral Perturbation Theory. Finally, in Appendix \ref{apex_model_av_t0} we sum up all the results for $t_0$ in physical units in the continuum and physical pion mass for each model explored for the chiral-continuum extrapolation.

