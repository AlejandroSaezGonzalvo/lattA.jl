\chapter*{Introduction}\addcontentsline{toc}{chapter}{Introduction}
\markboth{INTRODUCTION}{INTRODUCTION}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\label{ch_introduction}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


The Standard Model (SM) of particle physics is the theory that describes three of the four fundamental interactions in Nature: electromagnetism, the weak interaction, and the strong interaction. The theoretical framework in which the SM is formulated is that of Quantum Field Theory (QFT), and the particular theory that describes the strong interaction is Quantum Chromodynamics or QCD\footnote{The main discussion in this Introduction is based on the review~\citep{Wilczek:1998ma}, all other relevant references can be found in Chapter~\ref{ch_foundation}}.

\section*{Quantum Field Theory and the Standard Model}

The 20th century witnessed two pivotal developments in modern physics and our comprehension of Nature: special relativity and quantum mechanics. 

On the one hand, the theory of special relativity presents a reformulation of Galileo's principle, which prescribes that the laws of physics must remain unchanged in two different inertial frames. This reformulation is consistent with the theory of electromagnetism developed by Maxwell in the 19th century and posits that the speed of light is a universal constant. This led to profound consequences, such as time dilation and length contraction, according to which one observer experiences time and distances differently from another, depending on the relative speed of their inertial frames. Additionally, it implies the equivalence of mass and energy, and led to the formulation of the Universe as a 4-dimensional Lorentzian manifold, space-time, in which there is a non-trivial interplay between time and space.

The principle of a constant speed of light and the upper bound that it induces on the propagation speed of signals rendered the old Newtonian view of interactions obsolete. According to the latter, the force acting on a particle at a given time depends on the position of all other particles at that moment. This implies an instantaneous transfer of force from one particle to another, which is at odds with the principles of special relativity. Field Theory is the framework that allows to supersede this difficulty. It is based on the concept of fields, which are dynamic objects that fill the whole of space-time. Mathematically, they are simply functions of space and time. Treating fields as the fundamental degrees of freedom allows to construct a Lorentz invariant formulation of the theory which is thus compatible with special relativity. One example is Maxwell's theory of electromagnetism, which describes the dynamics of the electric $\vec{E}(\vec{x},t)$ and magnetic $\vec{B}(\vec{x},t)$ fields.

On the other hand, quantum mechanics introduces the concept of probability into our description of Nature. In this framework particles are described by wave functions that represent the probability density of finding a particle at a given position in space at some time. Position and momentum are promoted to conjugate operators that do not commute, which gives rise to Heisenberg's uncertainty principle, according to which it is not possible to know the position and momentum of a particle simultaneously
\begin{equation*}
\Delta x\Delta p\geq\hbar.
\end{equation*} 

Quantum Field Theory is the framework that unifies quantum mechanics and special relativity. It entails promoting classical fields to quantum operators in a manner analogous to the case of position and momentum in quantum mechanics. This results in a plethora of consequences, such as particles being regarded as excitations of an underlying quantum field, the existence of antiparticles or the non-conservation of particle number. The latter is of special importance for any quantum description of a relativistic system, as high-energy collisions can result in the creation and annihilation of  particles. Moreover, according to Heisenberg's uncertainty principle, if a particle is placed in a box of size $L$ there will be an uncertainty in its momentum of
\begin{equation*}
\Delta p\geq\hbar/L.
\end{equation*}
This gives rise to an uncertainty in the energy of the particle of order $\Delta E\geq\hbar c/L$. When the energy exceeds $2mc^2$ we have enough energy to create a particle-antiparticle pair from the vacuum, with $m$ the mass of the particle. This happens at distances of order 
\begin{equation*}
L=\lambda=\frac{\hbar}{mc},
\end{equation*}
which is the reduced Compton wavelength. At this and smaller distances (or equivalently higher energies) one expects to detect particle-antiparticle pairs in proximity to the original particle, breaking down the very concept of a point-like particle. 

Generalizing the concept of fields such that all particles are excitations of some field solves another puzzle of Nature: how can e.g. two electrons separated by a space-like distance (causally disconnected) look exactly the same, like two perfect copies of one another? This is naturally explained if there is a universal field of the electron, since all electrons are simply excitations of this field filling all of space-time. 

A key ingredient of QFTs are symmetries, which are defined in the mathematical framework of group theory. Global symmetries are of paramount importance in physics, as they provide conservation laws through Noether's Theorem, such as the conservation of energy and momentum. In addition to global symmetries, local or gauge symmetries also play a crucial role. These can be regarded as a redundancy in the theory, so that performing a local transformation of the fundamental fields leaves physics unchanged. Although it may appear impractical to write our theories of Nature in a redundant manner, it is very useful since it allows us to write simple Lagrangians which may have unphysical degrees of freedom that can be eliminated by using gauge redundancy. This is exemplified by the case of the photon, which has only two polarization states but in the SM is described by a gauge field with 4 degrees of freedom. Thanks to gauge symmetry, one can eliminate the two remaining unphysical degrees of freedom. Another beautiful property of gauge symmetries is that they allow for a geometric interpretation of interactions: gauge fields can be regarded as the connection in a principal G-bundle, with $G$ the gauge group, and the field strength tensor as the curvature. In this way, all fundamental interactions of Nature can be understood in the light of geometry, just as gravity is in General Relativity.

The gauge symmetry group of the SM is
\begin{equation*}
SU(3)_{\textrm{c}}\times SU(2)_{\textrm{w}}\times U(1)_{\textrm{Y}},
\end{equation*}
where $SU(3)_{\textrm{c}}$ is the gauge group of the strong interaction (whose charge is called color), $SU(2)_{\textrm{w}}$ is the gauge group of the weak interaction and $U(1)_{\textrm{Y}}$ is the gauge group of hypercharge. The Higgs mechanism provides a description of the spontaneous symmetry breaking of the electroweak sector $SU(2)_{\textrm{w}}\times U(1)_{\textrm{Y}}$ into that of electromagnetism $U(1)_{\textrm{em}}$, as well as a mechanism for the generation of masses for fundamental particles. The pure gauge interactions depend only on three free parameters, which are the three coupling constants. Matter fields do not introduce any further free parameter, while the addition of the Higgs field introduces 22 new free parameters into the theory, which govern the masses of the elementary particles, flavor mixing angles and CP-violating phases.

Over the decades, the SM has proven extremely successful in passing experimental tests. Notable examples include the discovery of neutral weak currents in 1973, the bottom quark in 1977, the Z and W bosons in 1983 and the agreement of the ratio of their masses between experiment and theory, the discovery of the top quark in 1995, and the Higgs boson in 2012. 

Despite the remarkable success of the SM, we know that it cannot be the whole story. On the one hand, it does not explain one of the four fundamental interactions of Nature, gravity. On the other hand, there's no candidate particle in the SM for dark matter, which is estimated to comprise $\sim85\%$ of the matter content in the Universe. In addition, there are other theoretical puzzles, such as the hierarchy problem of the Higgs mass, triviality of the Higgs coupling, the flavor puzzle or the strong CP problem, which we will briefly discuss below. The SM can thus be interpreted as an effective theory that describes extremely well the Universe at the energy scales probed by modern day colliders, but that there must be some New Physics (NP) at work at high energies, the search of which is the holy grail of modern day particle physics. 

One frontier of research for New Physics is the precision frontier. Modern particle physics experiments continue to improve the accuracy of a number of physical observables, and in order to detect possible NP signals, it is of the utmost importance to achieve a similar level of precision in theoretical predictions. One promising avenue for exploration is the study of B meson physics. Semileptonic B decays play a crucial role in the determination of the CKM matrix elements, and long-standing tensions exist between the exclusive and inclusive determinations of the elements $V_{ub}$ and $V_{cb}$~\citep{Ricciardi:2019zph}. In addition, in recent years some experimental anomalies have been observed in B meson decays, suggesting potential signals of the violation of lepton flavor universality. Currently, some prominent anomalies still persist  in the  $b\to c\tau\nu$ charged current and in the  $b\to s\ell^+\ell^-$ neutral current  decays~\citep{Capdevila:2023yhq}. Rare decays that in the SM are flavor-change-neutral-current  or GIM-suppressed  constitute excellent probes of NP effects. Yet another observable that has gained particular relevance in recent years is the anomalous magnetic moment of the muon, which has been measured experimentally with an unprecedented precision~\citep{Muong-2:2006rrc,PhysRevLett.131.161802}. However, theoretical consensus for this quantity is yet to be achieved: a data-driven dispersive approach leads to a $4.2\sigma$ tension with the experimental value~\citep{Aoyama:2020ynm}, while ab-initio SM calculations lead to a $1.5\sigma$ difference~\citep{Borsanyi:2020mff,Kuberski:2024bcj}. In all these processes QCD plays a crucial role, and thus precise theoretical predictions in this sector of the SM are of the utmost importance. The framework of Lattice Field Theory provides a first-principles method for performing these calculations.

\section*{Why Lattice Field Theory?}

In the intermediate steps of a calculation of physical observables in QFTs, there are often divergences that must be eliminated for the theory to remain predictive. This is achieved through the implementation of the renormalization program, which entails the subtraction of the divergences that emerge in physical quantities by means of the redefinition of the parameters of the theory that are not observables, such as bare field normalizations, masses and couplings. This renormalization program has been successfully applied to the three fundamental interactions described by the SM.

The renormalization process introduces a dependence of the renormalized couplings and masses  on the renormalization scale. This dependence is  constrained by the fact that the renormalization group running  must enforce that physical observables do not depend on the renormalization scale.  In the case of electromagnetism, the coupling (which is directly related to the electric charge of the electron) decreases at low energies. However, in the case of Yang-Mills theories such as QCD, the opposite is true, with the coupling becoming stronger at lower energies. 

In the weak coupling regime, where the coupling of a Quantum Field Theory is small, the theory can be studied through a perturbative expansion in powers of the coupling. This is the case of Quantum Electrodynamics at low energies, where high-order perturbative computations have been carried out over the years for quantities such as the charged lepton anomalous magnetic moment. In the case of QCD, however, the coupling grows at low energies and perturbation theory fails to perform theoretical predictions, as the system is governed by non-perturbative phenomena. The only known first-principles method for studying QFTs in the strong coupling regime is Lattice Field Theory. It consists of discretizing space-time into a finite volume Euclidean grid or lattice, with space-time points separated by a non-zero lattice spacing $a$, whose inverse plays the role of an ultraviolet cutoff. 

In Lattice Field Theory, the path integral  formalism can be cast into a statistical field theory system where a finite -- but very large -- number of integrals over the fields can be carried out numerically via Markov Chain Monte Carlo methods. This is a particularly suitable method to compute expectation values in a strongly coupled theory such as QCD, whose main distinguishing phenomena are non-perturbative. For instance, in the theory of the strong interaction non-perturbative effects are responsible for confinement, whereby no color charged particles are observed in Nature at low energies as asymptotic states. Spontaneous chiral symmetry breaking is yet another example of a non-perturbative effect responsible for the small mass of the pions. Additionally, the theory is expected to dynamically generate a mass gap due to its non-perturbative nature. This implies that the spectrum of QCD does not include any arbitrarily light particle. Even though this is experimentally confirmed and supported by Lattice Field Theory numerical simulations, there is, at the moment, no conclusive theoretical proof of the QCD mass gap. Obtaining a rigorous theoretical proof of its existence constitutes one of the famous Millennium Prize Problems~\citep{MillenniumPrizeproblems}. Another important aspect of QCD is its vacuum structure, the role of the $\theta$-term and topology of the gauge group. In order to advance in a comprehensive theoretical understanding of these features of QCD, as well as to conduct high precision, reliable calculations needed to improve the SM predictions and to contribute to the search of NP in the precision frontier, it is essential to employ a non-perturbative approach to the theory.

Non-perturbative treatment of QFT is also of great importance for other theoretical reasons. In many popular Beyond the Standard Model (BSM) scenarios, non-perturbative effects play a central role. For instance, in supersymmetric theories (SUSY), non-perturbative effects are invoked to break supersymmetry at low energies. Nearly conformal field theories and technicolor models (which retain some QCD-like properties at higher energy scales) also require a non-perturbative treatment.  Moreover, the SM version of the Higgs potential suffers from the triviality problem. This implies that the renormalized Higgs coupling vanishes after perturbative renormalization, unless there is a finite energy cutoff in the theory, implying that the SM is nothing but an Effective Field Theory (EFT) valid up to some energy cutoff. In this scenario, the Higgs mass is expected to receive large contributions from the high-energy scales, rendering it naturally heavy, in contrast to the observed value at CERN. This is referred to as the hierarchy problem. Non-perturbative numerical approaches demonstrate triviality of scalar field theories with a quartic interaction term~\citep{Luscher:1987ek} (which is the case of the Higgs potential in the SM). Nevertheless, the coupling of the scalar field to other SM particles could potentially alter the triviality behavior of the coupling. Once more, these issues can only be addressed by employing a non-perturbative approach. Consequently, Lattice Field Theory is a method for investigating a wide variety of fundamental physics problems in the SM and in QFT in general.

\section*{A Mixed Action Lattice approach to light and charm physics}

Having already motivated the need for precision calculations of SM physics involving the strong interaction in order to constrain the search for NP in experiments, the objective of this thesis is to define and implement a mixed action approach for the study of light and charm physics with Lattice QCD. This mixed action employs the Wilson fermion regularization for quarks in the sea, with mass degenerate up/down flavors plus a strange quark, and the Wilson twisted mass regularization for quarks in the valence, with up/down, strange and charm quarks. When tuning the twisted mass quarks at maximal twist, systematic effects of order $\mathcal{O}(a)$ arising from the discretization of space-time are expected to cancel, improving the scaling of physical observables towards the continuum. This is pertinent to the study of charm physics, given that the discretization effects associated with the charm quark are of order $\mathcal{O}(am_c)$ and large due to the heavy mass of the charm quark $m_c$. Consequently, our mixed action is expected to significantly aid in the extraction of precise charm observables with a controlled continuum limit.

The utilization of this mixed action breaks unitarity of the theory, even in the continuum, due to the use of different lattice regularizations for the sea and valence sectors. In order to account for this effect, it is necessary to ensure that the physical quark masses in both sectors are matched. Since the sea contains only up/down and strange quarks, it is necessary to adjust the parameters of the mixed action in order to impose that the valence up/down and strange physical quark masses are identical to those in the sea. This requires precise calculations in the light and strange sectors of QCD, which is the focus of this thesis.

In conjunction to this, in Lattice Field Theory every physical quantity is computed in units of the lattice spacing $a$. Consequently, in order to make predictions, one must first find the value of $a$ in physical units in order to convert any prediction on the lattice to physical units. This task is called scale setting, and it is the main focus of this thesis. As calculations in Lattice Field Theory have become increasingly precise in recent years, entering the ``precision era'' with uncertainties falling below $1\%$, setting the scale with high accuracy has become a primary focus of the community. This is because the determination of the scale affects any prediction of the theory. For example, the determination of the anomalous magnetic moment of the muon with subpercent accuracy requires setting the scale with a precision of a few permil~\citep{Borsanyi:2020mff}.

The thesis is structured as follows. In Chapter \ref{ch_foundation} we introduce the QCD action in the continuum and its gauge structure. We then consider how it can be formulated in a lattice with finite lattice spacing $a$. We elucidate the methodology for computing expectation values numerically, thereby bridging the gap between the path integral formalism in the Euclidean and statistical mechanics. We explain the procedure for taking the continuum limit and its relation to renormalizability. We review the Symanzik improvement program, which has the objective of reducing the discretization systematic effects and assisting in the task of taking the continuum limit. Furthermore, we elucidate the scale setting program. In Chapter \ref{ch_observables} we define all the relevant physical observables that we will require in this thesis and how they are extracted on the lattice. We also explain how to extract the ground state signals of these observables, isolating them from excited states, using model variation techniques. In Chapter \ref{ch_ma} we introduce our mixed action regularization. We explain the differences between the sea and valence sectors, and perform the matching between them to impose equal physical quark masses in both sectors. Simultaneously we tune the valence to maximal twist in order to obtain $\mathcal{O}(a)$ improvement. Furthermore, we introduce the line of constant physics followed and the mass shifting procedure needed to correct for small mistunings along it. In Chapter \ref{ch_ss} we perform the scale setting of our mixed action by computing the gradient flow scale $t_0$ in physical units, using as external physical input the decay constants of the pion and kaon. We explore a number of different models to perform the chiral extrapolation to the physical pion mass and the continuum limit at vanishing lattice spacing $a\to0$. We use model averaging techniques to compute a final average result of $t_0$ in physical units, taking into account the systematic uncertainty due to the model variation. Treating $t_0$ as an intermediate scale allows to extract the lattice spacing in fermi (fm). In Chapter \ref{ch_charm} we stress the impact of our scale setting procedure in the computation of hadronic computations involving the charm quark: using our determination of the scale $t_0$ we find results for the renormalized charm quark mass and $f_{D_{(s)}}$ decay constants in our mixed action setup, following our work in~\citep{charm}. Finally, we present our conclusions in Section~\ref{ch_conclu}.

This thesis is accompanied by a number of appendices. In Appendix \ref{appex_conventions} we present some conventions regarding the Gamma matrices, quark bilinears and the twisted and physical basis used in the different lattice regularizations. In Appendix~\ref{apex_SU3} we give the expressions for the Gell-Mann matrices and the $su(3)$ structure constants. In Appendix \ref{apex_ensembles} we review the gauge ensembles used in this work. We quote results for the relevant lattice observables computed in these ensembles in Appendix~\ref{apex_obs}. In Appendix \ref{appex_simulations} we review some useful simulation details of Lattice Field Theories. In Appendix \ref{appex_errors} we give details on the error propagation and treatment of (auto)correlations. In Appendix \ref{appex_solvers} we briefly discuss how the Dirac operator needed to compute n-point functions is inverted on the lattice. In Appendix \ref{apex_chisq} we give details on the fitting strategy we follow throughout this work. In Appendix \ref{apex_fv} we give expressions for the correction of finite volume effects as given by Chiral Perturbation Theory. In Appendix \ref{apex_light_qm} we present a preliminary analysis of the chiral-continuum extrapolation for the light and strange quark masses. Finally, in Appendix \ref{apex_model_av_t0} we summarize all the results for $t_0$ in physical units in the continuum and physical pion mass for each model explored for the chiral-continuum extrapolation.

