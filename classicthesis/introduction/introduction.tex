\chapter*{Introduction}\addcontentsline{toc}{chapter}{Introduction}
\markboth{INTRODUCTION}{INTRODUCTION}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\label{ch_introduction}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


The Standard Model (SM) of particle physics is the theory that describes three of the four fundamental interactions in Nature: electromagnetism, the weak interaction, and the strong interaction. The theoretical framework in which the SM is formulated is that of Quantum Field Theory (QFT), and the particular theory that describes the strong interaction is Quantum Chromodynamics or QCD\footnote{The main discussion in this Introduction is based on the review~\citep{Wilczek:1998ma}, all other relevant references can be found in Chapter~\ref{ch_foundation}}.

\section*{Quantum Field Theory and the Standard Model}

The 20th century witnessed two pivotal developments in modern physics and our comprehension of Nature: special relativity and quantum mechanics. 

On the one hand, the theory of special relativity presents a reformulation of Galileo's principle, which prescribes that the laws of physics must remain unchanged in two different inertial frames. This reformulation is consistent with the theory of electromagnetism developed by Maxwell in the 19th century and posits that the speed of light is a universal constant. This led to profound consequences, such as time dilation and length contraction, according to which one observer experiences time and distances differently from another, depending on the relative speed of their inertial frames. Additionally, it implies the equivalence of mass and energy, and led to the formulation of the Universe as a 4-dimensional Lorentzian manifold, space-time, in which there is a non-trivial interplay between time and space.

The principle of a constant speed of light and the upper bound that it induces on the propagation speed of signals rendered the old Newtonian view of interactions obsolete. According to the latter, the force acting on a particle at a given time depends on the position of all other particles at that moment. This implies an instantaneous transfer of force from one particle to another, which is at odds with the principles of special relativity. Field Theory is the framework that allows to supersede this difficulty. It is based on the concept of fields, which are dynamic objects that fill the whole of space-time. Mathematically, they are simply functions of space and time. Treating fields as the fundamental degrees of freedom allows to construct a Lorentz invariant formulation of the theory which is thus compatible with special relativity. One example is Maxwell's theory of electromagnetism, which describes the dynamics of the electric $\vec{E}(\vec{x},t)$ and magnetic $\vec{B}(\vec{x},t)$ fields.

On the other hand, quantum mechanics introduces the concept of probability into our description of Nature. In this framework particles are described by wave functions that represent the probability density of finding a particle at a given position in space at some time. Position and momentum are promoted to conjugate operators that do not commute, which gives rise to Heisenberg's uncertainty principle, according to which it is not possible to know the position and momentum of a particle simultaneously
\begin{equation*}
\Delta x\Delta p\geq\hbar.
\end{equation*} 

Quantum Field Theory is the framework that unifies quantum mechanics and special relativity. It entails promoting classical fields to quantum operators in a manner analogous to the case of position and momentum in quantum mechanics. This results in a plethora of consequences, such as particles being regarded as excitations of an underlying quantum field, the existence of antiparticles or the non-conservation of particle number. The latter is of special importance for any quantum description of a relativistic system, as high-energy collisions can result in the creation and annihilation of  particles. Moreover, according to Heisenberg's uncertainty principle, if a particle is placed in a box of size $L$ there will be an uncertainty in its momentum of
\begin{equation*}
\Delta p\geq\hbar/L.
\end{equation*}
This gives rise to an uncertainty in the energy of the particle of order $\Delta E\geq\hbar c/L$. When the energy exceeds $2mc^2$ we have enough energy to create a particle-antiparticle pair from the vacuum, with $m$ the mass of the particle. This happens at distances of order 
\begin{equation*}
L=\lambda=\frac{\hbar}{mc},
\end{equation*}
which is the reduced Compton wavelength. At this and smaller distances (or equivalently higher energies) one expects to detect particle-antiparticle pairs in proximity to the original particle, breaking down the very concept of a point-like particle. 

Generalizing the concept of fields such that all particles are excitations of some field solves another puzzle of Nature: how can e.g. two electrons separated by a space-like distance (causally disconnected) look exactly the same, like two perfect copies of one another? This is naturally explained if there is a universal field of the electron, since all electrons are simply excitations of this field filling all of space-time. 

A key ingredient of QFTs are symmetries, which are defined in the mathematical framework of group theory. Global symmetries are of paramount importance in physics, as they provide conservation laws through Noether's Theorem, such as the conservation of energy and momentum. In addition to global symmetries, local or gauge symmetries also play a crucial role. These can be regarded as a redundancy in the theory, so that performing a local transformation of the fundamental fields leaves physics unchanged. Although it may appear impractical to write our theories of Nature in a redundant manner, it is very useful since it allows us to write simple Lagrangians which may have unphysical degrees of freedom that can be eliminated by using gauge redundancy. This is exemplified by the case of the photon, which has only two polarization states but in the SM is described by a gauge field with 4 degrees of freedom. Thanks to gauge symmetry, one can eliminate the two remaining unphysical degrees of freedom. Another beautiful property of gauge symmetries is that they allow for a geometric interpretation of interactions: gauge fields can be regarded as the connection in a principal G-bundle, with $G$ the gauge group, and the field strength tensor as the curvature. In this way, all fundamental interactions of Nature can be understood in the light of geometry, just as gravity is in General Relativity.

The gauge symmetry group of the SM is
\begin{equation*}
SU(3)_{\textrm{c}}\times SU(2)_{\textrm{w}}\times U(1)_{\textrm{Y}},
\end{equation*}
where $SU(3)_{\textrm{c}}$ is the gauge group of the strong interaction (whose charge is called color), $SU(2)_{\textrm{w}}$ is the gauge group of the weak interaction and $U(1)_{\textrm{Y}}$ is the gauge group of hypercharge. The Higgs mechanism provides a description of the spontaneous symmetry breaking of the electroweak sector $SU(2)_{\textrm{w}}\times U(1)_{\textrm{Y}}$ into that of electromagnetism $U(1)_{\textrm{em}}$, as well as a mechanism for the generation of masses for fundamental particles. The pure gauge interactions depend only on three free parameters, which are the three coupling constants. Matter fields do not introduce any further free parameter, while the addition of the Higgs field introduces 22 new free parameters into the theory, which govern the masses of the elementary particles, flavor mixing angles and CP-violating phases.

Over the decades, the SM has proven extremely successful in passing experimental tests. Notable examples include the discovery of neutral weak currents in 1973, the bottom quark in 1977, the Z and W bosons in 1983 and the agreement of the ratio of their masses between experiment and theory, the discovery of the top quark in 1995, and the Higgs boson in 2012. 

Despite the remarkable success of the SM, we know that it cannot be the whole story. On the one hand, it does not explain one of the four fundamental interactions of Nature, gravity. On the other hand, there's no candidate particle in the SM for dark matter, which is estimated to comprise $\sim85\%$ of the matter content in the Universe. In addition, there are other theoretical puzzles, such as the hierarchy problem of the Higgs mass, triviality of the Higgs coupling, the flavor puzzle or the strong CP problem, which we will briefly discuss below. The SM can thus be interpreted as an effective theory that describes extremely well the Universe at the energy scales probed by modern day colliders, but that there must be some New Physics (NP) at work at high energies, the search of which is the holy grail of modern day particle physics. 

One frontier of research for New Physics is the precision frontier. Modern particle physics experiments continue to improve the accuracy of a number of physical observables, and in order to detect possible NP signals, it is of the utmost importance to achieve a similar level of precision in theoretical predictions. One promising avenue for exploration is the study of B meson physics. Semileptonic B decays play a crucial role in the determination of the CKM matrix elements, and long-standing tensions exist between the exclusive and inclusive determinations of the elements $V_{ub}$ and $V_{cb}$~\citep{Ricciardi:2019zph}. In addition, in recent years some experimental anomalies have been observed in B meson decays, suggesting potential signals of the violation of lepton flavor universality. Currently, some prominent anomalies still persist  in the  $b\to c\tau\nu$ charged current and in the  $b\to s\ell^+\ell^-$ neutral current  decays~\citep{Capdevila:2023yhq}. Rare decays that in the SM are flavor-change-neutral-current  or GIM-suppressed  constitute excellent probes of NP effects. Yet another observable that has gained particular relevance in recent years is the anomalous magnetic moment of the muon, which has been measured experimentally with an unprecedented precision~\citep{Muong-2:2006rrc,PhysRevLett.131.161802}. However, theoretical consensus for this quantity is yet to be achieved: a data-driven dispersive approach leads to a $4.2\sigma$ tension with the experimental value~\citep{Aoyama:2020ynm}, while ab-initio SM calculations lead to a $1.5\sigma$ difference~\citep{Borsanyi:2020mff,Kuberski:2024bcj}. In all these processes QCD plays a crucial role, and thus precise theoretical predictions in this sector of the SM are of the utmost importance. The framework of Lattice Field Theory provides a first-principles method for performing these calculations.

\section*{Why Lattice Field Theory?}

In the intermediate steps of a calculation of physical observables in QFTs, there are often divergences that must be eliminated for the theory to remain predictive. This is achieved through the implementation of the renormalization program, which entails the subtraction of the divergences that emerge in physical quantities by means of the redefinition of the parameters of the theory that are not observables, such as bare field normalizations, masses and couplings. This renormalization program has been successfully applied to the three fundamental interactions described by the SM.

The renormalization process introduces a dependence of the renormalized couplings and masses  on the renormalization scale. This dependence is  constrained by the fact that the renormalization group running  must enforce that physical observables do not depend on the renormalization scale.  In the case of electromagnetism, the coupling (which is directly related to the electric charge of the electron) decreases at low energies. However, in the case of Yang-Mills theories such as QCD, the opposite is true, with the coupling becoming stronger at lower energies. 

In the weak coupling regime, where the coupling of a Quantum Field Theory is small, the theory can be studied through a perturbative expansion in powers of the coupling. This is the case of Quantum Electrodynamics at low energies, where high-order perturbative computations have been carried out over the years for quantities such as the charged lepton anomalous magnetic moment. In the case of QCD, however, the coupling grows at low energies and perturbation theory fails to perform theoretical predictions, as the system is governed by non-perturbative phenomena. The only known first-principles method for studying QFTs in the strong coupling regime is Lattice Field Theory. It consists of discretizing space-time into a finite volume Euclidean grid or lattice, with space-time points separated by a non-zero lattice spacing $a$, whose inverse plays the role of an ultraviolet cutoff. 

In Lattice Field Theory, the path integral  formalism can be cast into a statistical field theory system where a finite -- but very large -- number of integrals over the fields can be carried out numerically via Markov Chain Monte Carlo methods. This is a particularly suitable method to compute expectation values in a strongly coupled theory such as QCD, whose main distinguishing phenomena are non-perturbative. For instance, in the theory of the strong interaction non-perturbative effects are responsible for confinement, whereby no color charged particles are observed in Nature at low energies as asymptotic states. Spontaneous chiral symmetry breaking is yet another example of a non-perturbative effect responsible for the small mass of the pions. Additionally, the theory is expected to dynamically generate a mass gap due to its non-perturbative nature. This implies that the spectrum of QCD does not include any arbitrarily light particle. Even though this is experimentally confirmed and supported by Lattice Field Theory numerical simulations, there is, at the moment, no conclusive theoretical proof of the QCD mass gap. Obtaining a rigorous theoretical proof of its existence constitutes one of the famous Millennium Prize Problems~\citep{MillenniumPrizeproblems}. Another important aspect of QCD is its vacuum structure, the role of the $\theta$-term and topology of the gauge group. In order to advance in a comprehensive theoretical understanding of these features of QCD, as well as to conduct high precision, reliable calculations needed to improve the SM predictions and to contribute to the search of NP in the precision frontier, it is essential to employ a non-perturbative approach to the theory.

Non-perturbative treatment of QFT is also of great importance for other theoretical reasons. In many popular Beyond the Standard Model (BSM) scenarios, non-perturbative effects play a central role. For instance, in supersymmetric theories (SUSY), non-perturbative effects are invoked to break supersymmetry at low energies. Nearly conformal field theories and technicolor models (which retain some QCD-like properties at higher energy scales) also require a non-perturbative treatment.  Moreover, the SM version of the Higgs potential suffers from the triviality problem. This implies that the renormalized Higgs coupling vanishes after perturbative renormalization, unless there is a finite energy cutoff in the theory, implying that the SM is nothing but an Effective Field Theory (EFT) valid up to some energy cutoff. In this scenario, the Higgs mass is expected to receive large contributions from the high-energy scales, rendering it naturally heavy, in contrast to the observed value at CERN. This is referred to as the hierarchy problem. Non-perturbative numerical approaches demonstrate triviality of scalar field theories with a quartic interaction term~\citep{Luscher:1987ek} (which is the case of the Higgs potential in the SM). Nevertheless, the coupling of the scalar field to other SM particles could potentially alter the triviality behavior of the coupling. Once more, these issues can only be addressed by employing a non-perturbative approach. Consequently, Lattice Field Theory is a method for investigating a wide variety of fundamental physics problems in the SM and in QFT in general.

\section*{A Mixed Action Lattice approach to light and charm physics}

Having motivated the need to study QCD in the context of Lattice Field Theory, the purpose of this research work is to construct and probe a lattice QCD approach that could contribute to improve the accuracy  of hadronic physics observables in the light- and charm-quark sectors. This is a timely initiative in the current context, where there is a need to improve the determination of the fundamental parameters of the SM, as well as of a whole class of observables currently studied in particle physics experiments. 

More specifically, we will consider a mixed action approach where different Dirac operators are employed in the sea and valence sectors. This mixed action setup employs the Wilson fermion regularization for quarks in the sea, with mass degenerate up/down quark flavors together with a strange quark, while Wilson twisted mass regularization for quarks are used in the valence sector, with up/down, strange and charm quarks. When the valence sector is tuned to the maximal twist, symmetry properties of the Wilson twisted-mass Dirac operator imply that the physical observables do not receive $\mathcal{O}(a)$ lattice artifacts, except for residual cutoff effects proportional to the sum of the masses of the sea quarks.
This provides an alternative way of obtaining results in the continuum limit, since lattice QCD calculations in this setup do not require the explicit determination of the set of $\mathcal{O}(a)$ improvement coefficients. This is particularly relevant for the study of charm quark physics, since the leading $\mathcal{O}(am_c)$ discretization effects associated with the charm quark can be sizeable due to the relatively large value of the charm quark mass $m_c$.  It is therefore interesting to consider an approach in which this source of lattice artifacts is absent.

In general, a mixed-action approach can induce unitarity violations in the continuum theory if the masses of the quarks of a given flavor are not correctly matched between the sea and valence sectors. This matching procedure is thus an important step of the calculation. Since the sea contains only up/down and strange quarks, it is necessary to adjust the parameters of the mixed action in order to impose that the valence up/down and strange physical quark masses coincide with those in the sea. This requires precise calculations in the light and strange sectors of QCD, which is one of the targets of this thesis.

In a lattice QCD calculation, the dimensional quantities are determined in units of the lattice spacing $a$. Physical input is required to fix the values of the fundamental parameters corresponding to the quark masses and the strong coupling. Such a scale setting procedure enables the determination of the values of  the lattice spacing used in the simulations, and any dimensional quantity to be quoted in physical units. In this work we will describe the implementation of a scale setting procedure based on the mixed action approach. As calculations in Lattice Field Theory have become increasingly precise in recent years, entering the ``precision era'' with uncertainties falling below $1\%$, setting the scale with high accuracy has become a primary focus of the community. This is because the uncertainty of the scale propagates into the accuracy of any given lattice observable. For example, for the hadronic  vacuum polarization contribution to the anomalous magnetic moment of the muon, which must be determined with a sub-percent accuracy, a significant sensitivity to the scale setting uncertainty has been established, requiring setting the scale with a precision of a few permil~\citep{Borsanyi:2020mff}.

The manuscript is structured as follows. In Chapter \ref{ch_foundation} we introduce the continuum QCD action and its gauge structure. We then consider how it can be formulated in a lattice with finite lattice spacing $a$. We present the methodology for computing expectation values numerically, thereby bridging the gap between the path integral formalism in Euclidean space-time and statistical mechanics. We establish the theoretical basis underlying the process of taking the continuum limit and its relation to renormalizability. We review the Symanzik improvement program, which is the effective field theory approach to parameterizing and improving the lattice spacing dependence of lattice observables. Finally, we elaborate on the scale setting program. In Chapter \ref{ch_observables} we define the relevant physical observables relevant in this work and how they are extracted on the lattice. We also explain how to extract the ground state signals of these observables, isolating them from excited states, using model variation techniques. In Chapter \ref{ch_ma} we introduce our mixed action regularization. We describe the regularizations used in the sea and valence sectors, and perform the matching procedure of the quark masses in both sectors. Simultaneously we tune the valence twisted mass Dirac operator to maximal twist. Furthermore, we describe the employed chiral trajectory towards the physical point and the mass-shift procedure used to correct for small mistunings. In Chapter \ref{ch_ss} we perform the scale setting of our mixed action by computing the gradient flow scale $t_0$ in physical units, using as external physical input the masses and decay constants of the pion and kaon. We explore a number of different models to perform the chiral extrapolation to the physical pion mass and the continuum limit at vanishing lattice spacing $a\to0$. We use model averaging techniques to compute a final average result of $t_0$ in physical units, taking into account the systematic uncertainty due to the model variation. Treating $t_0$ as an intermediate scale allows to extract the lattice spacing in fermi (fm). In Chapter \ref{ch_charm} we analyze the impact of our scale setting procedure in the computation of hadronic observables involving the charm quark: using our determination of the scale $t_0$ we obtain results for the renormalized charm quark mass and $D_{(s)}$ mesons decay constants based on our mixed action setup, following our work in~\citep{charm}. Finally, we present our conclusions in Section~\ref{ch_conclu}.

This thesis is accompanied by a number of appendices. In Appendix \ref{appex_conventions} we introduce conventions regarding the Gamma matrices, quark bilinears in the twisted and physical basis of the quark fields. In Appendix~\ref{apex_SU3} we provide the expressions for the Gell-Mann matrices and the $su(3)$ structure constants. In Appendix \ref{appex_simulations} we review some basic aspects of lattice simulations. In Appendix \ref{appex_solvers} we briefly discuss the methods employed to compute the quark propagators through the inversion of the Dirac operator. In Appendix \ref{appex_errors} we describe the methods used for error propagation and treatment of (auto)correlations. In Appendix \ref{apex_chisq} we give details on the fitting strategy followed throughout this work. In Appendix \ref{apex_GEVP} we give some brief details of the GEVP method employed for the computation of lattice observables involving the charm quark. In Appendix \ref{apex_ensembles} we review the gauge ensembles used in this work. We quote results for the relevant lattice observables computed in these ensembles in Appendix~\ref{apex_obs}. In Appendix \ref{apex_fv} we give expressions for the  finite volume effect corrections based on Chiral Perturbation Theory. In Appendix \ref{apex_model_av_t0} we report the results for $t_0$ in physical units  for each model considered for the chiral-continuum extrapolation. Finally, in Appendix \ref{apex_light_qm} we present a preliminary analysis of the chiral-continuum extrapolation for the light and strange quark masses. 

