\chapter*{Introducci\'on}\addcontentsline{toc}{chapter}{Introducci\'on}


El Modelo Estándar (SM) de la física de partículas es la teoría que describe tres de las cuatro interacciones fundamentales de la Naturaleza: el electromagnetismo, la interacción débil y la interacción fuerte. El marco teórico en el que se formula el SM es el de la Teoría Cuántica de Campos (QFT), y la teoría que describe la interacción fuerte es la Cromodinámica Cuántica o QCD\footnote{La discusión principal de esta Introducción se basa en la \textit{review}~\citep{Wilczek:1998ma}, el resto de referencias relevantes se pueden encontrar en el Capítulo~\ref{ch_foundation}}.

\section*{Teoría Cuántica de Campos y el Modelo Estándar}

El siglo XX fue testigo de dos desarrollos fundamentales en la física moderna y en nuestra comprensión de la Naturaleza: la relatividad especial y la mecánica cuántica. 

Por un lado, la teoría de la relatividad especial presenta una reformulación del principio de Galileo, el cual prescribe que las leyes de la física deben permanecer invariables en dos marcos de inercia diferentes. Dicha reformulación es coherente con la teoría del electromagnetismo desarrollada por Maxwell en el siglo XIX y postula que la velocidad de la luz es una constante universal. Esto condujo a profundas consecuencias, como la dilatación temporal y la contracción espacial, de manera que un observador experimenta el tiempo y las distancias de forma distinta a otro, dependiendo de la velocidad relativa de sus marcos inerciales. Además, implica la equivalencia de masa y energía, y condujo a la formulación del Universo como una variedad Lorentziana de 4 dimensiones, el espacio-tiempo, en el que existe una interrelación no trivial entre tiempo y espacio.

El principio de la velocidad constante de la luz y el límite superior que induce en la velocidad de propagación de las señales dejaron obsoleta la antigua visión newtoniana de las interacciones. Según esta última, la fuerza que actúa sobre una partícula en un momento dado depende de la posición de todas las demás partículas en ese momento. Esto implica una transferencia instantánea de las fuerzas de una partícula a otra, lo que contradice los principios de la relatividad especial. La Teoría de Campos es el marco que permite superar esta dificultad. Se basa en el concepto de campos, que son objetos dinámicos que llenan la totalidad del espacio-tiempo. Matemáticamente, un campo es simplemente una función del espacio y del tiempo. Tratar los campos como los grados de libertad fundamentales permite construir una formulación invariante de Lorentz de la teoría que, por tanto, es compatible con la relatividad especial. Un ejemplo es la teoría del electromagnetismo de Maxwell, que describe la dinámica de los campos $\vec{E}(\vec{x},t)$ eléctrico y $\vec{B}(\vec{x},t)$ magnético.

Por otro lado, la mecánica cuántica introduce el concepto de probabilidad en nuestra descripción de la Naturaleza. En este marco, las partículas son descritas mediante funciones de onda que representan la densidad de probabilidad de encontrar una partícula en una posición determinada del espacio en un momento dado. La posición y el momento se tratan como operadores conjugados que no conmutan, lo que da lugar al principio de incertidumbre de Heisenberg, según el cual no es posible conocer simultáneamente la posición y el momento de una partícula
\begin{equation*}
\Delta x\Delta p\geq\hbar.
\end{equation*} 

La Teoría Cuántica de Campos es el marco que unifica la mecánica cuántica y la relatividad especial. Implica la promoción de campos clásicos a operadores cuánticos de forma análoga al caso de la posición y el momento en la mecánica cuántica. De ello se derivan numerosas consecuencias, como la consideración de las partículas como excitaciones de un campo cuántico subyacente, la existencia de antipartículas o la no conservación del número de partículas. Esto último es de especial importancia para cualquier descripción cuántica de un sistema relativista, ya que las colisiones de alta energía pueden dar lugar a la creación y aniquilación de partículas. Además, según el principio de incertidumbre de Heisenberg, si una partícula se coloca en una caja de tamaño $L$ habrá una incertidumbre en su momento de
\begin{equation*}
\Delta p\geq\hbar/L.
\end{equation*}
Esto da lugar a una incertidumbre en la energía de la partícula del orden $\Delta E\geq\hbar c/L$. Cuando la energía supera $2mc^2$ tenemos energía suficiente para crear un par partícula-antipartícula a partir del vacío, siendo $m$ la masa de la partícula. Esto ocurre a distancias del orden 
\begin{equation*}
L=\lambda=\frac{\hbar}{mc},
\end{equation*}
que es la longitud de onda Compton reducida. A esta distancia y a distancias más pequeñas (o equivalentemente a energías más altas) uno espera detectar pares partícula-antipartícula en proximidad de la partícula original, rompiendo el concepto mismo de partícula puntual. 

Generalizar el concepto de campo de tal manera que todas las partículas sean excitaciones de algún campo resuelve otro enigma de la Naturaleza: ¿cómo es posible, por ejemplo, que dos electrones separados por una distancia \textit{space-like} (causalmente desconectados) parezcan exactamente iguales, como dos copias perfectas el uno del otro? Esto queda resuelto si existe un campo universal del electrón llenando todo el espacio-tiempo, ya que todos los electrones son simplemente excitaciones de este campo. 


Un ingrediente clave de las QFT son las simetrías, que se definen en el marco matemático de la teoría de grupos. Las simetrías globales son de vital importancia en física, ya que proporcionan leyes de conservación a través del Teorema de Noether, como la conservación de la energía y el momento. Además de las simetrías globales, las simetrías locales o gauge también desempeñan un papel crucial. Estas pueden considerarse una redundancia en la teoría, de modo que al realizar una transformación local de los campos fundamentales la física no cambia. Aunque pueda parecer poco práctico escribir nuestras teorías de la Naturaleza de forma redundante, es muy útil ya que nos permite escribir Lagrangianos simples con grados de libertad no físicos, que pueden eliminarse utilizando la redundancia gauge. Esto se ejemplifica con el caso del fotón, que sólo tiene dos estados de polarización pero en el SM está descrito por un campo gauge con 4 grados de libertad. Gracias a la simetría gauge, se pueden eliminar los dos grados de libertad no físicos restantes. Otra propiedad de las simetrías gauge es que permiten una interpretación geométrica de las interacciones: los campos gauge pueden considerarse como la conexión en un \textit{principal G-bundle}, con $G$ el grupo gauge, y el \textit{field-strenght} tensor como la curvatura. De este modo, todas las interacciones fundamentales de la Naturaleza pueden interpretarse de manera geométrica, al igual que la gravedad en la Relatividad General.

El grupo de simetría gauge del SM es
\begin{equation*}
SU(3)_{\textrm{c}}\times SU(2)_{\textrm{w}}\times U(1)_{\textrm{Y}},
\end{equation*}
donde $SU(3)_{\textrm{c}}$ es el grupo gauge de la interacción fuerte (cuya carga se denomina color), $SU(2)_{\textrm{w}}$ es el grupo gauge de la interacción débil y $U(1)_{\textrm{Y}}$ es el grupo gauge de la hipercarga. El mecanismo de Higgs proporciona una descripción de la ruptura espontánea de simetría del sector electrodébil $SU(2)_{\textrm{w}}\times U(1)_{\textrm{Y}}$ al del electromagnetismo $U(1)_{\textrm{em}}$, así como un mecanismo para la generación de masas para las partículas fundamentales. Las interacciones gauge puras dependen sólo de tres parámetros libres, que son las tres constantes de acoplamiento. Los campos de materia no introducen ningún otro parámetro libre, mientras que la adición del campo de Higgs introduce 22 nuevos parámetros libres en la teoría, que gobiernan las masas de las partículas elementales, los ángulos de mezcla de sabores y las fases de violación CP.

A lo largo de las décadas, el SM ha superado con éxito las pruebas experimentales. Ejemplos notables son el descubrimiento de las corrientes débiles neutras en 1973, el quark \textit{bottom} en 1977, los bosones Z y W en 1983 y la concordancia de la relación de sus masas entre el experimento y la teoría, el descubrimiento del quark \textit{top} en 1995 y el bosón de Higgs en 2012. 

A pesar del notable éxito del SM, sabemos que no puede ser el fin de la historia. Por un lado, no explica una de las cuatro interacciones fundamentales de la Naturaleza, la gravedad. Por otro lado, no hay ninguna partícula candidata en el SM para la materia oscura, que se estima que comprende el $\sim85\%$ del contenido de materia en el Universo. Además, existen otros enigmas teóricos, como el problema de jerarquía de la masa de Higgs, la trivialidad del acoplamiento de Higgs, el enigma del sabor o el problema de CP fuerte, que discutiremos brevemente a continuación. Así pues, el SM puede interpretarse como una teoría efectiva que describe extremadamente bien el Universo a las escalas de energía sondeadas por los colisionadores actuales, pero que debe haber Nueva Física (NP) trabajando a altas energías, cuya búsqueda es el santo grial de la física de partículas actual. 


Una de las fronteras de investigación para la Nueva Física es la frontera de precisión. Los experimentos modernos de física de partículas siguen mejorando la precisión de una serie de observables físicos y, para detectar posibles señales de NP, es de suma importancia alcanzar un nivel similar de precisión en las predicciones teóricas. Una vía de exploración prometedora es el estudio de la física del mesón B. Las desintegraciones semileptónicas de B juegan un papel crucial en la determinación de los elementos de la matriz CKM, y existen tensiones desde hace mucho tiempo entre las determinaciones exclusivas e inclusivas de los elementos $V_{ub}$ y $V_{cb}$~\citep{Ricciardi:2019zph}. Además, en los últimos años se han observado algunas anomalías experimentales en las desintegraciones del mesón B, que sugieren señales potenciales de violación de la universalidad del sabor leptónico. Actualmente, aún persisten algunas anomalías prominentes en la corriente cargada $b\to c\tau\nu$ y en las desintegraciones de corriente neutra $b\to s\ell^+\ell^-$~\citep{Capdevila:2023yhq}. Las desintegraciones raras que en el SM están suprimidas por el cambio de sabor de la corriente neutra o por el mecanismo de GIM constituyen excelentes sondas de los efectos NP. Otro observable que ha cobrado especial relevancia en los últimos años es el momento magnético anómalo del muón, que se ha medido experimentalmente con una precisión sin precedentes~\citep{Muong-2:2006rrc,PhysRevLett.131.161802}. Sin embargo, aún no se ha alcanzado un consenso teórico para esta cantidad: un enfoque basado en datos experimentales conduce a una tensión de $4.2\sigma$ con el valor experimental~\citep{Aoyama:2020ynm}, mientras que los cálculos SM \textit{ab-initio} conducen a una diferencia de $1.5\sigma$~\citep{Borsanyi:2020mff,Kuberski:2024bcj}. En todos estos procesos QCD juega un papel crucial, por lo que las predicciones teóricas precisas en este sector del SM son de suma importancia. El marco de la Teoría de Campos en el Retículo proporciona un método basado en primeros principios para realizar estos cálculos.

\section*{¿Por qué la Teoría de Campos en el Retículo?}

En los pasos intermedios de los cálculos de observables físicos en QFTs, a menudo hay divergencias que deben ser eliminadas para que la teoría siga siendo predictiva. Esto se consigue mediante la implementación del programa de renormalización, que implica la sustracción de las divergencias que surgen en las cantidades físicas mediante la redefinición de los parámetros de la teoría que no son observables, tales como normalizaciones de campo, masas y constantes de acoplo \textit{bare}. Este programa de renormalización se ha aplicado con éxito a las tres interacciones fundamentales descritas por el SM.

El proceso de renormalización introduce una dependencia de los acoplamientos y masas renormalizados con respecto a la escala de renormalización. Esta dependencia está limitada por el hecho de que el grupo de renormalización debe garantizar que los observables físicos no dependan de la escala de renormalización.  En el caso del electromagnetismo, la constante de acoplo (que está directamente relacionada con la carga eléctrica del electrón) disminuye a bajas energías. Sin embargo, en el caso de las teorías de Yang-Mills como QCD, ocurre lo contrario, y el acoplamiento se hace más fuerte a bajas energías. 

En el régimen de acoplamiento débil, en el que la constante de acoplo de una Teoría Cuántica de Campos es pequeña, la teoría puede estudiarse mediante una expansión perturbativa en potencias de la constante de acoplo. Este es el caso de la Electrodinámica Cuántica a bajas energías, donde a lo largo de los años se han llevado a cabo cálculos perturbativos de alto orden para cantidades como el momento magnético anómalo del leptón cargado. En el caso de QCD, sin embargo, la constante de acoplo crece a bajas energías y la teoría de perturbaciones falla a la hora de realizar predicciones teóricas, ya que el sistema está gobernado por fenómenos no perturbativos. El único método basado en primeros principios conocido para estudiar QFTs en el régimen de acoplamiento fuerte es la Teoría de Campos en el Retículo. Esta consiste en discretizar el espacio-tiempo en un retículo Euclídeo de volumen finito, con los puntos del espacio-tiempo separados por un espaciado reticular $a$ mayor que cero, cuyo inverso desempeña el papel de un \textit{cutoff} ultravioleta. 


En la teoría de campos en el retículo, el formalismo de la integral de caminos puede transformarse en un sistema estadístico de campos en el que un número finito -pero muy grande- de integrales sobre los campos puede llevarse a cabo numéricamente mediante métodos de Monte Carlo de cadenas de Markov. Se trata de un método especialmente adecuado para calcular valores esperados en una teoría fuertemente acoplada como QCD, cuyos principales fenómenos distintivos son no-perturbativos. Por ejemplo, en la teoría de la interacción fuerte los efectos no-perturbativos son responsables del confinamiento, por el cual no se observan partículas con carga de color en la Naturaleza a bajas energías como estados asintóticos. La ruptura espontánea de simetría quiral es otro ejemplo de efecto no perturbativo, responsable de la pequeña masa de los piones. Además, se espera que la teoría genere dinámicamente una brecha de masa debido a su naturaleza no-perturbativa. Esto implica que el espectro de QCD no incluye ninguna partícula arbitrariamente ligera. Aunque esto está confirmado experimentalmente y apoyado por simulaciones numéricas de la Teoría de Campos en el Retículo, no existe, por el momento, ninguna prueba teórica concluyente de la brecha de masa en QCD. Obtener una prueba teórica rigurosa de su existencia constituye uno de los famosos Problemas del Premio del Milenio~\citep{MillenniumPrizeproblems}. Otro aspecto importante de QCD es su estructura de vacío, el papel del término $\theta$ y la topología del grupo gauge. Para avanzar en una comprensión teórica exhaustiva de estas características de QCD, así como para realizar cálculos fiables de alta precisión necesarios para mejorar las predicciones del SM y contribuir a la búsqueda de NP en la frontera de precisión, es esencial emplear un enfoque no-perturbativo de la teoría.

El tratamiento no-perturbativo de las QFTs es también de gran importancia por otras razones teóricas. En muchos escenarios populares más allá del Modelo Estándar (BSM), los efectos no-perturbativos juegan un papel central. Por ejemplo, en las teorías supersimétricas (SUSY), se invocan efectos no perturbativos para romper la supersimetría a bajas energías. Las teorías de campos casi conformes y los modelos \textit{technicolor} (que conservan algunas propiedades similares a QCD a escalas de energía más altas) también requieren un tratamiento no-perturbativo.  Además, la versión en el SM del potencial de Higgs sufre el problema de la trivialidad. Esto implica que el acoplamiento de Higgs renormalizado se anula tras la renormalización perturbativa, a menos que exista un \textit{cutoff} de energía finito en la teoría, lo que implica que el SM no es más que una Teoría de Campos Efectiva (EFT) válida hasta cierto \textit{cutoff} de energía. En este escenario, se espera que la masa de Higgs reciba grandes contribuciones de las escalas de alta energía, haciéndola naturalmente pesada, en contraste con el valor observado en el CERN. Esto se conoce como el problema de la jerarquía. Cálculos numéricos no-perturbativos demuestran la trivialidad de las teorías de campo escalar con un término de interacción cuártico~\citep{Luscher:1987ek} (que es el caso del potencial de Higgs en el SM). Sin embargo, el acoplamiento del campo escalar a otras partículas del SM podría alterar potencialmente el comportamiento de trivialidad. Una vez más, estas cuestiones sólo pueden abordarse empleando un enfoque no-perturbativo. En consecuencia, la Teoría de Campos en el Retículo es un método para investigar una amplia variedad de problemas de física fundamental en el SM y en el contexto de las QFTs en general.

\section*{Una acción mixta en el retículo para estudiar física de quarks ligeros y el charm} 

Una vez motivada la necesidad del estudio de QCD en el contexto de la Teoría de Campos en el Retículo, el propósito de este trabajo de investigación es construir y explorar una aproximación a QCD en el retículo que pueda contribuir a mejorar la precisión de los observables de la física hadrónica en los sectores de quarks ligeros y \textit{charm}. Se trata de una iniciativa oportuna en el contexto actual, en el que es necesario mejorar la determinación de los parámetros fundamentales del SM, así como de toda una clase de observables estudiados actualmente en experimentos de física de partículas. 

Más concretamente, consideraremos un enfoque de acción mixta en el que se emplean diferentes operadores de Dirac en los sectores mar y valencia. Este \textit{setup} de acción mixta emplea la regularización fermiónica de Wilson para los quarks en el mar, con sabores de quark \textit{up}/\textit{down} con masa degenerada junto con un quark \textit{strange}, mientras que la regularización de Wilson \textit{twisted mass} es utilizada en el sector de valencia, con quarks \textit{up}/\textit{down}, \textit{strange} y \textit{charm}. Cuando el sector de valencia se ajusta a máximo \textit{twist}, las propiedades de simetría del operador de Dirac de Wilson \textit{twisted mass} implican que los observables físicos no reciben artefactos reticulares $\mathcal{O}(a)$, excepto por efectos residuales proporcionales a la suma de las masas de los quarks del mar.
Esto proporciona una forma alternativa de obtener resultados en el límite del continuo, ya que los cálculos de QCD en el retículo en este \textit{setup} no requieren la determinación explícita del conjunto de coeficientes de $\mathcal{O}(a)$ \textit{improvement}. Esto es particularmente relevante para el estudio de la física del quark \textit{charm}, ya que los efectos de discretización $\mathcal{O}(am_c)$ asociados al quark \textit{charm} pueden ser considerables debido al valor relativamente grande de la masa del quark \textit{charm} $m_c$.  Por lo tanto, es interesante considerar un enfoque en el que esta fuente de artefactos reticulares esté ausente.

En general, una acción mixta puede inducir violaciones de unitaridad en la teoría del continuo si las masas de los quarks de un determinado sabor no coinciden entre los sectores mar y valencia. Este procedimiento de \textit{matching} es, por tanto, un paso importante del cálculo. Puesto que el mar sólo contiene quarks \textit{up}/\textit{down} y \textit{strange}, es necesario ajustar los parámetros de la acción mixta para imponer que las masas de los quarks físicos \textit{up}/\textit{down} y \textit{strange} de valencia coincidan con las del mar. Esto requiere cálculos precisos en los sectores ligero y \textit{strange} de QCD, que es uno de los objetivos de esta tesis.


En un cálculo de QCD en el retículo, las cantidades físicas se determinan en unidades del espaciado reticular $a$. Se requiere un \textit{input} físico para fijar los valores de los parámetros fundamentales correspondientes a las masas de los quarks y a la constante de acoplo fuerte. Este procedimiento de \textit{scale setting} permite determinar los valores del espaciado reticular utilizado en las simulaciones, y obtener cualquier cantidad física en unidades físicas. En este trabajo describiremos la implementación de un procedimiento de \textit{scale setting} basado en el enfoque de acción mixta. Dado que los cálculos en la Teoría de Campos en el Retículo se han vuelto cada vez más precisos en los últimos años, entrando en la ``era de la precisión'' con incertidumbres que caen por debajo de $1\%$, el establecimiento de la escala con alta precisión se ha convertido en un objetivo primordial de la comunidad. Esto se debe a que la incertidumbre de la escala se propaga en la precisión de cualquier observable reticular. Por ejemplo, para la contribución hadrónica de la polarización del vacío al momento magnético anómalo del muón, que debe determinarse con una precisión inferior al $1\%$, se ha establecido una sensibilidad significativa a la incertidumbre en el \textit{scale setting}, lo que requiere establecer la escala con una precisión de unos pocos permil~\citep{Borsanyi:2020mff}.

El manuscrito está estructurado como sigue. En el capítulo \ref{ch_foundation} introducimos la acción QCD del continuo y su estructura gauge. A continuación consideramos cómo puede formularse en una red con espaciado reticular finito $a$. Presentamos la metodología para calcular numéricamente valores esperados, salvando así la distancia entre el formalismo de la integral de caminos en el espacio-tiempo Euclideo y la mecánica estadística. Establecemos la base teórica que subyace al proceso de tomar el límite al continuo y su relación con la renormalizabilidad. Revisamos el programa de \textit{improvement} de Symanzik, que es el enfoque de la Teoría de Campos Efectiva para parametrizar y mejorar la dependencia del espaciado reticular de los observables reticulares. Finalmente, elaboramos el programa de \textit{scale setting}. En el capítulo \ref{ch_observables} definimos los observables físicos relevantes en este trabajo y cómo se extraen en el retículo. También explicamos cómo extraer las señales de estado de mínima energía de estos observables, aislándolas de los estados excitados, utilizando técnicas de variación sobre modelos. En el capítulo \ref{ch_ma} introducimos nuestra regularización de acción mixta. Describimos las regularizaciones utilizadas en los sectores mar y valencia, y realizamos el procedimiento de ajuste de las masas de los quarks en ambos sectores. Simultáneamente ajustamos el operador de Dirac \textit{twisted mass} de valencia a máximo \textit{twist}. Además, describimos la trayectoria quiral empleada hacia el punto físico y el procedimiento para corregir pequeños \textit{mistunings}. En el capítulo \ref{ch_ss} realizamos el ajuste de escala de nuestra acción mixta calculando la escala $t_0$ en unidades físicas, utilizando como \textit{input} físico externa las masas y constantes de desintegración del pión y el kaón. Exploramos una serie de modelos diferentes para llevar a cabo la extrapolación quiral a la masa física del pión y el límite al continuo a un espaciado de red $a\to0$. Utilizamos técnicas de variación sobre modelos para calcular un resultado medio final de $t_0$ en unidades físicas, teniendo en cuenta la incertidumbre sistemática debida a la variación de los modelos. Tratar $t_0$ como una escala intermedia permite extraer el espaciado de red en fermi (fm). En el capítulo \ref{ch_charm} analizamos el impacto de nuestro procedimiento de \textit{scale setting} en el cálculo de observables hadrónicos que involucran al quark \textit{charm}: utilizando nuestra determinación de la escala $t_0$ obtenemos resultados para la masa renormalizada del quark \textit{charm} y las constantes de desintegración de los mesones $D_{(s)}$ basados en nuestro \textit{setup} de acción mixta, siguiendo nuestro trabajo en~\citep{charm}. Finalmente, presentamos nuestras conclusiones en la sección~\ref{ch_conclu}.

Esta tesis va acompañada de una serie de apéndices. En el apéndice \ref{appex_conventions} introducimos convenciones relativas a las matrices Gamma, bilineales de quarks en la base física y \textit{twisted} de los campos de quarks. En el Apéndice~\ref{apex_SU3} proporcionamos las expresiones para las matrices de Gell-Mann y las constantes de estructura $su(3)$. En el Apéndice \ref{appex_simulations} revisamos algunos aspectos básicos de las simulaciones reticulares. En el Apéndice \ref{appex_solvers} discutimos brevemente los métodos empleados para calcular los propagadores de los quarks a través de la inversión del operador de Dirac. En el Apéndice \ref{appex_errors} describimos los métodos utilizados para la propagación de errores y el tratamiento de las (auto)correlaciones. En el Apéndice \ref{apex_chisq} damos detalles sobre la estrategia de \textit{fit} seguida a lo largo de este trabajo. En el Apéndice \ref{apex_GEVP} damos unos breves detalles del método GEVP empleado para el cálculo de los observables reticulares que implican al quark \textit{charm}. En el Apéndice \ref{apex_ensembles} revisamos los \textit{ensembles} gauge utilizados en este trabajo. En el Apéndice~\ref{apex_obs} citamos los resultados para los observables reticulares relevantes calculados en estos \textit{ensembles}. En el Apéndice \ref{apex_fv} damos expresiones para las correcciones del efecto de volumen finito basadas en la Teoría de Perturbaciones Quiral. En el Apéndice \ref{apex_model_av_t0} presentamos los resultados para $t_0$ en unidades físicas para cada modelo considerado para la extrapolación quiral-continuo. Finalmente, en el Apéndice \ref{apex_light_qm} presentamos un análisis preliminar de la extrapolación quiral-continuo para las masas de los quarks ligeros y \textit{strange}. 
