\chapter*{Introducci\'on}\addcontentsline{toc}{chapter}{Introducci\'on}


El Modelo Estándar (SM) de la física de partículas es la teoría que describe tres de las cuatro interacciones fundamentales de la Naturaleza: el electromagnetismo, la interacción débil y la interacción fuerte. El marco teórico en el que se formula el SM es el de la Teoría Cuántica de Campos (QFT), y la teoría que describe la interacción fuerte es la Cromodinámica Cuántica o QCD\footnote{La discusión principal de esta Introducción se basa en la \textit{review}~\citep{Wilczek:1998ma}, el resto de referencias relevantes se pueden encontrar en el Capítulo~\ref{ch_foundation}}.

\section*{Teoría Cuántica de Campos y el Modelo Estándar}

El siglo XX fue testigo de dos desarrollos fundamentales en la física moderna y en nuestra comprensión de la Naturaleza: la relatividad especial y la mecánica cuántica. 

Por un lado, la teoría de la relatividad especial presenta una reformulación del principio de Galileo, que prescribe que las leyes de la física deben permanecer invariables en dos marcos de inercia diferentes. Dicha reformulación es coherente con la teoría del electromagnetismo desarrollada por Maxwell en el siglo XIX y postula que la velocidad de la luz es una constante universal. Esto condujo a profundas consecuencias, como la dilatación del tiempo y la contracción de las longitudes, de manera que un observador experimenta el tiempo y las distancias de forma distinta a otro, dependiendo de la velocidad relativa de sus marcos inerciales. Además, implica la equivalencia de masa y energía, y condujo a la formulación del Universo como una variedad Lorentziana de 4 dimensiones, el espacio-tiempo, en el que existe una interacción no trivial entre tiempo y espacio.

El principio de la velocidad constante de la luz y el límite superior que induce en la velocidad de propagación de las señales dejaron obsoleta la antigua visión newtoniana de las interacciones. Según esta última, la fuerza que actúa sobre una partícula en un momento dado depende de la posición de todas las demás partículas en ese momento. Esto implica una transferencia instantánea de las fuerzas de una partícula a otra, lo que contradice los principios de la relatividad especial. La Teoría de Campos es el marco que permite superar esta dificultad. Se basa en el concepto de campos, que son objetos dinámicos que llenan la totalidad del espacio-tiempo. Matemáticamente, un campo es simplemente una función del espacio y del tiempo. Tratar los campos como los grados de libertad fundamentales permite construir una formulación invariante de Lorentz de la teoría que, por tanto, es compatible con la relatividad especial. Un ejemplo es la teoría del electromagnetismo de Maxwell, que describe la dinámica de los campos $\vec{E}(\vec{x},t)$ eléctrico y $\vec{B}(\vec{x},t)$ magnético.

Por otro lado, la mecánica cuántica introduce el concepto de probabilidad en nuestra descripción de la Naturaleza. En este marco, las partículas son descritas mediante funciones de onda que representan la densidad de probabilidad de encontrar una partícula en una posición determinada del espacio en un momento dado. La posición y el momento se tratan como operadores conjugados que no conmutan, lo que da lugar al principio de incertidumbre de Heisenberg, según el cual no es posible conocer simultáneamente la posición y el momento de una partícula
\begin{equation*}
\Delta x\Delta p\geq\hbar.
\end{equation*} 

La Teoría Cuántica de Campos es el marco que unifica la mecánica cuántica y la relatividad especial. Implica la promoción de campos clásicos a operadores cuánticos de forma análoga al caso de la posición y el momento en la mecánica cuántica. De ello se derivan numerosas consecuencias, como la consideración de las partículas como excitaciones de un campo cuántico subyacente, la existencia de antipartículas o la no conservación del número de partículas. Esto último es de especial importancia para cualquier descripción cuántica de un sistema relativista, ya que las colisiones de alta energía pueden dar lugar a la creación y aniquilación de partículas. Además, según el principio de incertidumbre de Heisenberg, si una partícula se coloca en una caja de tamaño $L$ habrá una incertidumbre en su momento de
\begin{equation*}
\delta p\geq\hbar/L.
\end{equation*}
Esto da lugar a una incertidumbre en la energía de la partícula del orden $\Delta E\geq\hbar c/L$. Cuando la energía supera $2mc^2$ tenemos energía suficiente para crear un par partícula-antipartícula a partir del vacío, siendo $m$ la masa de la partícula. Esto ocurre a distancias del orden 
\begin{equation*}
L=\lambda=\frac{\hbar}{mc},
\end{equation*}
que es la longitud de onda Compton reducida. A esta distancia y a distancias más pequeñas (o equivalentemente a energías más altas) uno espera detectar pares partícula-antipartícula en proximidad de la partícula original, rompiendo el concepto mismo de partícula puntual. 

Generalizar el concepto de campo de tal manera que todas las partículas sean excitaciones de algún campo resuelve otro enigma de la Naturaleza: ¿cómo es posible, por ejemplo, que dos electrones separados por una distancia \textit{space-like} (causalmente desconectados) parezcan exactamente iguales, como dos copias perfectas el uno del otro? Esto queda resuelto si existe un campo universal del electrón llenando todo el espacio-tiempo, ya que todos los electrones son simplemente excitaciones de este campo. 


Un ingrediente clave de las QFT son las simetrías, que se definen en el marco matemático de la teoría de grupos. Las simetrías globales son de vital importancia en física, ya que proporcionan leyes de conservación a través del Teorema de Noether, como la conservación de la energía y el momento. Además de las simetrías globales, las simetrías locales o gauge también desempeñan un papel crucial. Estas pueden considerarse una redundancia en la teoría, de modo que al realizar una transformación local de los campos fundamentales la física no cambia. Aunque pueda parecer poco práctico escribir nuestras teorías de la Naturaleza de forma redundante, es muy útil ya que nos permite escribir Lagrangianos simples con grados de libertad no físicos, que pueden eliminarse utilizando la redundancia gauge. Esto se ejemplifica con el caso del fotón, que sólo tiene dos estados de polarización pero en el SM está descrito por un campo gauge con 4 grados de libertad. Gracias a la simetría gauge, se pueden eliminar los dos grados de libertad no físicos restantes. Otra propiedad de las simetrías gauge es que permiten una interpretación geométrica de las interacciones: los campos gauge pueden considerarse como la conexión en un \textit{principal G-bundle}, con $G$ el grupo gauge, y el \textit{field-strenght} tensor como la curvatura. De este modo, todas las interacciones fundamentales de la Naturaleza pueden interpretarse de manera geométrica, al igual que la gravedad en la Relatividad General.

El grupo de simetría gauge del SM es
\begin{equation*}
SU(3)_{\textrm{c}}\times SU(2)_{\textrm{w}}\times U(1)_{\textrm{Y}},
\end{equation*}
donde $SU(3)_{\textrm{c}}$ es el grupo gauge de la interacción fuerte (cuya carga se denomina color), $SU(2)_{\textrm{w}}$ es el grupo gauge de la interacción débil y $U(1)_{\textrm{Y}}$ es el grupo gauge de la hipercarga. El mecanismo de Higgs proporciona una descripción de la ruptura espontánea de simetría del sector electrodébil $SU(2)_{\textrm{w}}\times U(1)_{\textrm{Y}}$ al del electromagnetismo $U(1)_{\textrm{em}}$, así como un mecanismo para la generación de masas para las partículas fundamentales. Las interacciones gauge puras dependen sólo de tres parámetros libres, que son las tres constantes de acoplamiento. Los campos de materia no introducen ningún otro parámetro libre, mientras que la adición del campo de Higgs introduce 22 nuevos parámetros libres en la teoría, que gobiernan las masas de las partículas elementales, los ángulos de mezcla de sabores y las fases de violación CP.

A lo largo de las décadas, el SM ha superado con éxito las pruebas experimentales. Ejemplos notables son el descubrimiento de las corrientes débiles neutras en 1973, el quark \textit{bottom} en 1977, los bosones Z y W en 1983 y la concordancia de la relación de sus masas entre el experimento y la teoría, el descubrimiento del quark \textit{top} en 1995 y el bosón de Higgs en 2012. 

A pesar del notable éxito del SM, sabemos que no puede ser el fin de la historia. Por un lado, no explica una de las cuatro interacciones fundamentales de la Naturaleza, la gravedad. Por otro lado, no hay ninguna partícula candidata en el SM para la materia oscura, que se estima que comprende el $\sim85\%$ del contenido de materia en el Universo. Además, existen otros enigmas teóricos, como el problema de jerarquía de la masa de Higgs, la trivialidad del acoplamiento de Higgs, el enigma del sabor o el problema de CP fuerte, que discutiremos brevemente a continuación. Así pues, el SM puede interpretarse como una teoría efectiva que describe extremadamente bien el Universo a las escalas de energía sondeadas por los colisionadores actuales, pero que debe haber Nueva Física (NP) trabajando a altas energías, cuya búsqueda es el santo grial de la física de partículas actual. 


Una de las fronteras de investigación para la Nueva Física es la de precisión. Los experimentos modernos de física de partículas siguen mejorando la precisión de una serie de observables físicos y, para detectar posibles señales de NP, es de suma importancia alcanzar un nivel similar de precisión en las predicciones teóricas. Una vía de exploración prometedora es el estudio de la física del mesón B. Las desintegraciones semileptónicas de B juegan un papel crucial en la determinación de los elementos de la matriz CKM, y existen tensiones desde hace mucho tiempo entre las determinaciones exclusivas e inclusivas de los elementos $V_{ub}$ y $V_{cb}$~\citep{Ricciardi:2019zph}. Además, en los últimos años se han observado algunas anomalías experimentales en las desintegraciones del mesón B, que sugieren señales potenciales de violación de la universalidad del sabor leptónico. Actualmente, aún persisten algunas anomalías prominentes en la corriente cargada $b\to c\tau\nu$ y en las desintegraciones de corriente neutra $b\to s\ell^+\ell^-$~\citep{Capdevila:2023yhq}. Las desintegraciones raras que en el SM están suprimidas por el cambio de sabor de la corriente neutra o por el mecanismo de GIM constituyen excelentes sondas de los efectos NP. Otro observable que ha cobrado especial relevancia en los últimos años es el momento magnético anómalo del muón, que se ha medido experimentalmente con una precisión sin precedentes~\citep{Muong-2:2006rrc,PhysRevLett.131.161802}. Sin embargo, aún no se ha alcanzado un consenso teórico para esta cantidad: un enfoque basado en datos experimentales conduce a una tensión de $4.2\sigma$ con el valor experimental~\citep{Aoyama:2020ynm}, mientras que los cálculos SM \textit{ab-initio} conducen a una diferencia de $1.5\sigma$~\citep{Borsanyi:2020mff,Kuberski:2024bcj}. En todos estos procesos QCD juega un papel crucial, por lo que las predicciones teóricas precisas en este sector del SM son de suma importancia. El marco de la Teoría de Campos en el Retículo proporciona un método basado en primeros principios para realizar estos cálculos.

\section*{¿Por qué la Teoría de Campos en el Retículo?}

En los pasos intermedios de los cálculos de observables físicos en QFTs, a menudo hay divergencias que deben ser eliminadas para que la teoría siga siendo predictiva. Esto se consigue mediante la implementación del programa de renormalización, que implica la sustracción de las divergencias que surgen en las cantidades físicas mediante la redefinición de los parámetros de la teoría que no son observables, tales como normalizaciones de campo, masas y constantes de acoplo \textit{bare}. Este programa de renormalización se ha aplicado con éxito a las tres interacciones fundamentales descritas por el SM.

El proceso de renormalización introduce una dependencia de los acoplamientos y masas renormalizados con respecto a la escala de renormalización. Esta dependencia está limitada por el hecho de que el grupo de renormalización debe garantizar que los observables físicos no dependan de la escala de renormalización.  En el caso del electromagnetismo, la constante de acoplo (que está directamente relacionada con la carga eléctrica del electrón) disminuye a bajas energías. Sin embargo, en el caso de las teorías de Yang-Mills como QCD, ocurre lo contrario, y el acoplamiento se hace más fuerte a bajas energías. 

En el régimen de acoplamiento débil, en el que la constante de acoplo de una Teoría Cuántica de Campos es pequeña, la teoría puede estudiarse mediante una expansión perturbativa en potencias de la constante de acoplo. Este es el caso de la Electrodinámica Cuántica a bajas energías, donde a lo largo de los años se han llevado a cabo cálculos perturbativos de alto orden para cantidades como el momento magnético anómalo del leptón cargado. En el caso de QCD, sin embargo, la constante de acoplo crece a bajas energías y la teoría de perturbaciones falla a la hora de realizar predicciones teóricas, ya que el sistema está gobernado por fenómenos no perturbativos. El único método basado en primeros principios conocido para estudiar QFTs en el régimen de acoplamiento fuerte es la Teoría de Campos en el Retículo. Esta consiste en discretizar el espacio-tiempo en un retículo Euclídeo de volumen finito, con los puntos del espacio-tiempo separados por un espaciado reticular $a$ mayor que cero, cuyo inverso desempeña el papel de un \textit{cutoff} ultravioleta. 


En la teoría de campos en el retículo, el formalismo de la integral de caminos puede transformarse en un sistema estadístico de campos en el que un número finito -pero muy grande- de integrales sobre los campos puede llevarse a cabo numéricamente mediante métodos de Monte Carlo de cadenas de Markov. Se trata de un método especialmente adecuado para calcular valores esperados en una teoría fuertemente acoplada como QCD, cuyos principales fenómenos distintivos son no-perturbativos. Por ejemplo, en la teoría de la interacción fuerte los efectos no-perturbativos son responsables del confinamiento, por el cual no se observan partículas con carga de color en la Naturaleza a bajas energías como estados asintóticos. La ruptura espontánea de simetría quiral es otro ejemplo de efecto no perturbativo, responsable de la pequeña masa de los piones. Además, se espera que la teoría genere dinámicamente una brecha de masa debido a su naturaleza no-perturbativa. Esto implica que el espectro de QCD no incluye ninguna partícula arbitrariamente ligera. Aunque esto está confirmado experimentalmente y apoyado por simulaciones numéricas de la Teoría de Campos en el Retículo, no existe, por el momento, ninguna prueba teórica concluyente de la brecha de masa en QCD. Obtener una prueba teórica rigurosa de su existencia constituye uno de los famosos Problemas del Premio del Milenio~\citep{MillenniumPrizeproblems}. Otro aspecto importante de QCD es su estructura de vacío, el papel del término $\theta$ y la topología del grupo gauge. Para avanzar en una comprensión teórica exhaustiva de estas características de QCD, así como para realizar cálculos fiables de alta precisión necesarios para mejorar las predicciones del SM y contribuir a la búsqueda de NP en la frontera de precisión, es esencial emplear un enfoque no-perturbativo de la teoría.

El tratamiento no-perturbativo de las QFTs es también de gran importancia por otras razones teóricas. En muchos escenarios populares más allá del Modelo Estándar (BSM), los efectos no-perturbativos juegan un papel central. Por ejemplo, en las teorías supersimétricas (SUSY), se invocan efectos no perturbativos para romper la supersimetría a bajas energías. Las teorías de campos casi conformes y los modelos \textit{technicolor} (que conservan algunas propiedades similares a QCD a escalas de energía más altas) también requieren un tratamiento no-perturbativo.  Además, la versión en el SM del potencial de Higgs sufre el problema de la trivialidad. Esto implica que el acoplamiento de Higgs renormalizado se anula tras la renormalización perturbativa, a menos que exista un \textit{cutoff} de energía finito en la teoría, lo que implica que el SM no es más que una Teoría de Campos Efectiva (EFT) válida hasta cierto \textit{cutoff} de energía. En este escenario, se espera que la masa de Higgs reciba grandes contribuciones de las escalas de alta energía, haciéndola naturalmente pesada, en contraste con el valor observado en el CERN. Esto se conoce como el problema de la jerarquía. Cálculos numéricos no-perturbativos demuestran la trivialidad de las teorías de campo escalar con un término de interacción cuártico~\citep{Luscher:1987ek} (que es el caso del potencial de Higgs en el SM). Sin embargo, el acoplamiento del campo escalar a otras partículas del SM podría alterar potencialmente el comportamiento de trivialidad. Una vez más, estas cuestiones sólo pueden abordarse empleando un enfoque no-perturbativo. En consecuencia, la Teoría de Campos en el Retículo es un método para investigar una amplia variedad de problemas de física fundamental en el SM y en el contexto de las QFTs en general.

\section*{Una acción mixta en el retículo para estudiar física de quarks ligeros y el charm} 
